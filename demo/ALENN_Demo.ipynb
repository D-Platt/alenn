{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALENN - Demo Notebook\n",
    "## Quickstart Guide\n",
    "\n",
    "Donovan Platt\n",
    "<br>\n",
    "Mathematical Institute, University of Oxford\n",
    "<br>\n",
    "Institute for New Economic Thinking at the Oxford Martin School\n",
    "<br>\n",
    "<br>\n",
    "Copyright (c) 2020, University of Oxford. All rights reserved.\n",
    "<br>\n",
    "Distributed under a BSD 3-Clause licence. See the accompanying LICENCE file for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook provides, through the use of a simple illustrative example, a complete tutorial on the use of the ALENN package to perform Bayesian estimation for economic simulation models using the neural network-based approach introduced by Platt (2021) in the paper *[Bayesian Estimation of Economic Simulation Models Using Neural Networks](https://link.springer.com/article/10.1007/s10614-021-10095-9)*. In general, the workflow presented here should require minimal adjustment (changing the model function, empirical dataset, priors, and sampler settings) in order to be applied to new examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "## Importing of Packages\n",
    "As a natural starting point, we begin by importing any required Python packages. With the exception of ALENN, which we assume has already been installed as per the instructions provided in the accompanying README file, all other imported libraries are now fairly standard in most data science workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the ALENN ABM Estimation Package\n",
    "import alenn\n",
    "\n",
    "# Import Plotting Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Numerical Computation Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import General Mathematical Libraries\n",
    "from scipy import stats\n",
    "\n",
    "# Import Data Storage Libraries\n",
    "import pickle as pkl\n",
    "\n",
    "# Import System Libraries\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable Tensorflow Deprecation Warnings\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# Tensorflow 2.x deprecates many Tensorflow 1.x methods, causing Tensorflow 1.15.0 to output a large number \n",
    "# of (harmless) deprecation warnings when performing the first likelihood calculation. This can be very \n",
    "# distracting, leading us to disable them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "## Creating the Likelihood and Posterior Estimator Object\n",
    "The primary functionally of ALENN is implemented in the `MDNPosterior` class, which contains all the methods required to estimate the likelihood and posterior. It thus follows that the first step in the estimation pipeline is creating an `MDNPosterior` object by calling its constructor method, `alenn.mdn.MDNPosterior`.\n",
    "<br>\n",
    "<br>\n",
    "If no arguments are provided to the constructor, the default neural network architecture introduced in the paper is used. If an alternative is required, however, this can easily be specified through the use of keyword arguments. As an example, increasing the number of lags to 4 and decreasing the number of hidden layers to 2 could be achieved by calling `alenn.mdn.MDNPosterior(num_lags = 4, num_layers = 2)`. Further details can be obtained by consulting the class docstring: \n",
    "```python\n",
    "?alenn.mdn.MDNPosterior\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Successfully created a new MDN object:\n",
      "--------------------------------------\n",
      "Number of lags:                3                   \n",
      "Number of mixture components:  16                  \n",
      "Number of neurons per layer:   32                  \n",
      "Number of hidden layers:       3                   \n",
      "Batch size:                    512                 \n",
      "Number of epochs:              12                  \n",
      "Activation function:           relu                \n",
      "Input noise:                   0.2                 \n",
      "Output noise:                  0.2                 \n",
      "--------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an MDN Posterior Approximator Object (Uses Default Settings from the Paper)\n",
    "posterior = alenn.mdn.MDNPosterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "## Specifying the Candidate Model\n",
    "At this stage, all we have done is defined a generic posterior estimator object. In order to actually apply the estimator to a given problem, we need to provide the object with additional information. We begin with the candidate model.\n",
    "<br>\n",
    "<br>\n",
    "From the perspective of ALENN, the model is a black box capable of producing simulated time series data. Therefore, the candidate model is provided to ALENN in the form of a function that takes in a 1-d numpy array or list of parameter values and returns a model output matrix as a 2-d numpy array. Ensuring that the model is correctly specified and matches ALENN's input, processing, and output requirements is perhaps the most critical part of this process and should therefore be approached with care.\n",
    "<br>\n",
    "<br>\n",
    "To elaborate, the model function should take, as input, a 1-d numpy array, $\\mathbf{\\theta}$, containing values for each of the model's free parameters (those that should be estimated). The function should then proceed to generate a corresponding set of $R$ model Monte Carlo replications. Each of these replications is a single time series of length $T_{sim}$ generated by the model for the same set of parameter values as the remaining replications, $\\mathbf{\\theta}$, but a different random seed, $i$. Once generated, each replication should be stored as a single column in a $T_{sim} \\times R$ numpy array that is returned as the final output by the model function.\n",
    "<br>\n",
    "<br>\n",
    "It is important to note that, although the choice of seed for each replication is arbitrary, the same set of seeds must be used throughout the entire estimation experiment, i.e. the model function should always use the same set of seeds, regardless of the value of $\\mathbf{\\theta}$ at which the function is evaluated. Footnote 44 in the paper provides a more detailed discussion. Additionally, in most practical examples, the generation of simulated data using the candidate model is likely to be computationally-expensive and thus a bottleneck in the inference process. We therefore suggest that, if the model is costly to simulate, that the model function should generate the replications in parallel.\n",
    "<br>\n",
    "<br>\n",
    "Finally, as suggested by the model function output structure introduced above, this version of ALENN currently only supports univariate time series model outputs. Note, however, that the methodology itself is generally applicable to multivariate outputs and a multivariate extension to this library is likely to be released in the near future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model function successfully set.\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the Simulated Data Characteristics\n",
    "T_sim = 1000    # Length of each Monte Carlo replication\n",
    "R = 100         # Number of Monte Carlo replications\n",
    "seed_set = 7    # The set of seeds associated with the model replications\n",
    "\n",
    "# In most cases, we suggest that either (T_sim = 1000 and R = 100) or (T_sim = 2000 and R = 50) be considered.\n",
    "# The seed_set variable can be interpreted as defining an arbitrary set of 100 random seeds.\n",
    "\n",
    "# Define the Candidate Model Function\n",
    "def model(theta):\n",
    "    return np.diff(alenn.models.random_walk(700, 0.4, 0.5, theta[0], theta[1], T_sim, R, seed_set), axis = 0)\n",
    "\n",
    "# Add the Model Function to the MDNPosterior Object\n",
    "posterior.set_model(model)\n",
    "\n",
    "# In the above, we have selected the random walk examined in the paper's comparative experiments. This model, \n",
    "# along with the other models considered in the paper, are implemented as part of ALENN and can be accessed via\n",
    "# alenn.models as above (see the corresponding file for more details). \n",
    "#\n",
    "# In this case, we are attempting to estimate the pre- and post-break volatility and have fixed all other parameters \n",
    "# to their default values. Notice that we also consider the series of first differences to induce stationarity. \n",
    "# While stationarity is not an assumption of the methodology, it may be advantageous to consider stationarity \n",
    "# transformations if a given non-stationary model proves to be difficult to estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "## Specifying the Model Priors\n",
    "As in any Bayesian exercise, we must specify a prior over the model parameters. In ALENN, the prior is specified\n",
    "in the form of a special data structure. A prior function must be defined separately for each free parameter and each function of this type should take in a single value for that parameter and return a corresponding prior density value. These functions should be stored in a Python list.\n",
    "<br>\n",
    "<br>\n",
    "In all cases, the order of the density functions in the prior list must correspond to the order in which the parameters are passed to the model function. More concretely, if the model function takes in values for parameters $[\\sigma_1, \\sigma_2]$, the prior list must have form $[p(\\sigma_1), p(\\sigma_2)]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prior successfully set. The model has 2 free parameters.\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define Parameter Priors\n",
    "priors = [stats.uniform(loc = 0, scale = 10).pdf,\n",
    "          stats.uniform(loc = 0, scale = 10).pdf]\n",
    "\n",
    "# Add the Model Priors to the MDNPosterior Object\n",
    "posterior.set_prior(priors)\n",
    "\n",
    "# In the above, we have defined uniform priors over [0, 10] for both the pre- and post-break volatility. In most \n",
    "# applications, we recommend that users make use of SciPy's stats module to define the priors, as we have. This \n",
    "# results in greater readability and can help avoid errors in the prior specification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "## Loading the Empirical Data\n",
    "To complete the problem specification, we are finally required to provide the `MDNPosterior` object with a set of empirical data. This process is rather straightforward and simply requires that the data be provided in the form of a 1-d numpy array.\n",
    "<br>\n",
    "<br>\n",
    "While longer empirical time series are always preferred if available, we typically consider $T_{emp} = 1000$ for problems involving $1-4$ free parameters and $T_{emp} = 2000$ for problems involving $5-10$ free parameters. In many cases, however, we suspect that a significant reduction in the number of data points would be viable, particularly when the data provides a reasonable level of information regarding the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical data successfully loaded. There are 999 observations in total.\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Empirical Data\n",
    "with open('data/Demo_Data', 'rb') as f:\n",
    "    empirical = pkl.load(f)\n",
    "\n",
    "# Add the Empirical Data to the MDNPosterior Object\n",
    "posterior.load_data(empirical)\n",
    "\n",
    "# The empirical data loaded above is a synthetic series of 999 (first-differenced) observations generated by the\n",
    "# random walk model when initialised using the parameter values associated with the first free parameter set \n",
    "# introduced in the paper's comparative exercises. Our exercise here can thus be seen as a replication of the\n",
    "# associated comparative experiment.\n",
    "#\n",
    "# In a true empirical application, this series would simply be replaced by a series measured from the actual\n",
    "# real-world system being modelled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6\n",
    "## Sampling the Posterior\n",
    "With the `MDNPosterior` object now completely specified, we are able to evaluate the posterior for arbitrary values of $\\mathbf{\\theta}$ and hence sample it using MCMC. As discussed in detail in Appendix 2, we make use of the adaptive Metropolis-Hastings algorithm proposed by Griffin and Walker (2013).\n",
    "<br>\n",
    "<br>\n",
    "As in the case of the posterior, the sampler is also implemented as an object, in this case being an instantiation of the `AdaptiveMCMC` class. In order to perform the sampling procedure, a number of key components must be specified and passed to the object. These include:\n",
    "* Parameter ranges over which to conduct the initial sweep of the parameter space. This is specified in the form of two 1-d numpy arrays that contain, in the same order as is associated with the list of priors discussed in Step 4, the lower and upper bounds for each parameter respectively.\n",
    "* The desired number of samples per sample set. In general, we recommend that this is set to $K = 70$.\n",
    "* The desired number of sample sets to be generated. As a rule of thumb, we suggest generating $S = 5000$ sets for problems involving $1 - 4$ free parameters and $15000$ sets for problems involving $5 - 10$ free parameters. Of course, common convergence diagnostics, such as Galman and Ruben's R, could certainly be used to ensure that a sufficient number of samples has been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Successfully created a new MCMC sampler object:\n",
      "-----------------------------------------------\n",
      "Number of sample sets:         5000                \n",
      "Number of samples per set:     70                  \n",
      "-----------------------------------------------\n",
      "\n",
      "MDNPosterior object successfully loaded.\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Initialisation ranges successfully set.\n",
      "\n",
      "           Lower Bound  Upper Bound\n",
      "Parameter                          \n",
      "1                    0           10\n",
      "2                    0           10\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an Adaptive MCMC Sampler Object\n",
    "sampler = alenn.mcmc.AdaptiveMCMC(K = 70, S = 5000)\n",
    "\n",
    "# Define the Parameter Bounds\n",
    "theta_lower = np.array([0, 0])\n",
    "theta_upper = np.array([10, 10])\n",
    "\n",
    "# Add the Posterior Approximator and Parameter Ranges to the Newly-created Object\n",
    "sampler.set_posterior(posterior)\n",
    "sampler.set_initialisation_ranges(theta_lower, theta_upper)\n",
    "\n",
    "# Please note that the set_posterior method must be called before the set_initialisation_ranges method.\n",
    "\n",
    "# Initiate the Sampling Process\n",
    "sampler.sample_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7\n",
    "## Processing the Obtained Samples\n",
    "Once the sampling procedure has concluded, all that remains is the processing of the obtained samples into meaningful outputs, i.e. tables or marginal posterior plots.\n",
    "<br>\n",
    "<br>\n",
    "The aforementioned samples may be extracted from the `AdaptiveMCMC` object using the `process_samples` method, which requires the specification of a single integer argument, `burn_in`. This argument specifies the number of sample sets that should be discarded as part of an initial burning-in period, as is standard in all MCMC algorithms, and we typically recommend burning-in periods of $1500-2500$ sample sets for $S = 5000$ and $7500-10000$ sample sets for $S = 15000$. Of course, some problems may require alternative configurations depending on their associated convergence rates and we therefore recommend that multiple chains be generated by repeating Step 6 several times in order to diagnose convergence when applying the methodology.\n",
    "<br>\n",
    "<br>\n",
    "The `process_samples` method returns the obtained samples in the form of a 2-d numpy array, where each column represents the posterior samples obtained for a given parameter, with the columns following the same parameter order as the original model function. The method output also contains a final, extra column consisting of the the associated log-likelihood samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Estimation Results:\n",
      "\n",
      "           Posterior Mean  Posterior Std. Dev.\n",
      "Parameter                                     \n",
      "1                0.946465             0.032059\n",
      "2                1.951355             0.102465\n"
     ]
    }
   ],
   "source": [
    "# Result Table\n",
    "\n",
    "# Note that we illustrate the construction of a result table for a single chain, whereas the corresponding result\n",
    "# in Section 4.1 is associated with 5 chains.\n",
    "\n",
    "# Process the Sampler Output\n",
    "samples = sampler.process_samples(burn_in = 2500)\n",
    "\n",
    "# Calculate the Posterior Mean\n",
    "pos_mean = samples[:, :posterior.num_param].mean(axis = 0)\n",
    "\n",
    "# Calculate the Posterior Standard Deviation\n",
    "pos_std = samples[:, :posterior.num_param].std(axis = 0)\n",
    "\n",
    "# Construct a Result Table\n",
    "result_table = pd.DataFrame(np.array([pos_mean, pos_std]).transpose(), columns = ['Posterior Mean', 'Posterior Std. Dev.'])\n",
    "result_table.index.name = 'Parameter'\n",
    "result_table.index += 1\n",
    "\n",
    "# Display the Result Table\n",
    "print('Final Estimation Results:')\n",
    "print('')\n",
    "print(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Marginal Posterior Plots\n",
    "\n",
    "# Note that we illustrate the construction of marginal posterior plots for a single chain, whereas the corresponding \n",
    "# result in Section 4.1 is associated with 5 chains.\n",
    "\n",
    "# Process the Sampler Output\n",
    "samples = sampler.process_samples(burn_in = 2500)\n",
    "\n",
    "# Set the Parameter Names\n",
    "param_names = [r'$\\sigma_1$', r'$\\sigma_2$']\n",
    "\n",
    "# Set-Up the Figure\n",
    "fig = plt.figure(figsize = (5 * posterior.num_param, 5))\n",
    "\n",
    "# Loop Over the Free Parameters\n",
    "for i in range(posterior.num_param):\n",
    "    \n",
    "    # Plot the Posterior Histogram\n",
    "    plt.subplot(1, posterior.num_param, i + 1)\n",
    "    plt.hist(samples[:, i], 25, density = True, color = 'b', alpha = 0.5)\n",
    "    \n",
    "    # Plot the Prior Density\n",
    "    prior_range = np.linspace(samples[:, i].min() * 0.9, samples[:, i].max() * 1.1, 100)\n",
    "    plt.plot(prior_range, [priors[i](x) for x in prior_range], color = 'r', alpha = 0.75)\n",
    "    \n",
    "    # Note that we are only plotting the prior for a limited range such that it extends only slightly\n",
    "    # beyond the posterior. This is done to improve the clarity of presentation. In reality, the prior is \n",
    "    # substantially wider than the posterior and would extend from 0 to 10 for this example.\n",
    "    \n",
    "    # Plot the Posterior Mean\n",
    "    plt.axvline(x = samples[:, i].mean(), c = 'k', linestyle = 'dashed', alpha = 0.75)\n",
    "    \n",
    "    # Label the Plot\n",
    "    plt.xlabel(param_names[i])\n",
    "    plt.ylabel(r'$p($' + param_names[i] + r'$)$')\n",
    "    plt.legend(['Prior Density', 'Posterior Mean', 'Posterior Density'], fontsize = 8)\n",
    "\n",
    "# Set the Figure Layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the Figure\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
